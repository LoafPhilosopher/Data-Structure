[TOC]

# 算法

## 算法的概念

### 定义

算法是指基于特定的计算模型，旨在解决某一信息处理问题而设计的一个**指令序列**

### 算法的特征

- 输入：待处理的信息（问题）
- 输出：经处理的信息（答案）
- 确定性：可描述为一个由基本操作组成的序列
- 可行性：每一基本操作都可实现，且在常数时间内完成
- 有穷性与正确性：对于任何输入，经过有穷次基本操作，都可以得到输出

### 好算法的目标

<font color="red">

$$
好算法=正确+健壮+可读+效率_{(最重要)}
$$

</font>

- 正确性。算法应能够正确地解决求解问题。
- 健壮性。输入非法数据时，算法能适当地做出反应或进行处理，而不会产生莫名其妙的输出结果。
- 可读性。算法应具有良好的可读性，以帮助人们理解。准确命名+注释
- 效率:速度尽可能快，存储空间尽可能少

## <font color="red">复杂度度量</font>

**算法的分析主要分为两方面：**

1. **正确性**
2. **运行时间+所需的存储空间**

### 时间复杂度

一般地，问题规模越接近，相应的计算成本也越接近；而随着问题规模的扩大，计算成本通常也呈上升趋势。因此将执行时间的这一变化趋势表示为输入规模的一个函数，称为**时间复杂度**。具体的，特定算法处理规模为$n$的问题所需的时间可记为 $T(n)$。但是规模相同不一定确保输入相同，因此对上述定义的 $T(n)$ 进行简化，即从保守估计的角度出发，**在规模为 $n$ 的所有输入中选择执行时间最长者作为 $T(n)$ ，并以 $T(n)$ 度量该算法的时间复杂度。**

### 渐进复杂度

我们想分析当 n 足够大时的时间复杂度，因此需要进行渐进分析。

- 大 $\mathcal{O}$ 记号:首先关注 $T(n)$ 的渐进上界，因此引入大 $\mathcal{O}$ 记号。大 $\mathcal{O}$具有如下性质:
  - 对于任一常数：$c>0$,有 $O(f(n))= O(c\cdot f(n))$。即在大 $\mathcal{O}$记号的影响下，函数各项正的常系数可以忽略并等同于 1
  - 对于任意常数：$\mathrm{a~>b~>0,~}$ 有 $O(\mathrm{n}^a+\mathrm{n}^b)= O(\mathrm{n}^a)$。即多项式中的低次项均可被忽略，只需保留最高次项。
- 环境差异：在实际环境中直接测得的执行时间 $T(n)$，虽然可以作为衡量算法性能的一种指标，但不能作为评判不同算法性能优劣的标准。因为即便是同一算法、同一输入，在不同的硬件平台上、不同的操作系统中甚至不同的时间，所需要的计算时间都不尽相同。
- 基本操作：**将时间复杂度理解为算法中各条指令的执行时间之和。** 因此只需统计出该算法所执行基本操作的总次数，即可确定$T(n)$的上界。
- 大$\Omega$记号：如果存在正的常数 $c$ 和函数 $g(n)$ ,使得对于任何$n>>2$都有：$\mathrm{T(n)\geq c\cdot g(n)}$,因此可以认为当 n 足够大时，g(n)给出了一个 $T(n)$ 的渐进下界，记为 $\mathrm{T(n)}=\Omega(\mathrm{g(n)})$。即对于任何规模的 n 的输入，算法的运行时间都不低于 $\Omega(g(n))$。
- 大$\Theta$记号：借助上述$\mathcal{O}$和$\Omega$可以对算法时间复杂度作出定量的界定。从渐进的趋势来看，$T(n)$介于$\Omega(g(n))$和$O(f(n))$之间。若恰好出现$g(n)=f(n)$的情况，则可以使用另一种记号来表示。如果存在正的常数 $c_1 < c_2$和函数 $h(n)$，使得对于任何 $n>2$ 都有$\mathrm{c_1\cdotp h(n)~\leq~T(n)~\leq~c_2\cdotp h(n)}$当$n$足够大时，$h(n)$给出了一个$T(n)$的一个确界。记为$\mathrm{T(n)}=\Theta(\mathrm{h(n)})。$ **它是对算法复杂度的准确估计--对于规模为$n$的任何输入，算法的运行时间$T(n)$都与$\Theta(\mathrm{h(n)})$同阶.**
  ![20240307222128](https://yjc-figure.oss-cn-beijing.aliyuncs.com/20240307222128.png)

### 空间复杂度

除了执行时间的长短,算法所需存储空间的多少也是衡量其性能的一个重要方面,此即所谓的空间复杂度(space complexity)。实际上,以上针对时间复杂度所引入的几种渐进记号,也适用于对空间复杂度的度量,其原理及方法基本相同,不再赘述.

## 复杂度分析

### 常数复杂度$O(1)$

运行时间可表示和度量为$T(n) = O(1)$的这一类算法，统称作"常数时间复杂度算法"(constant-time algorithm)。此类算法已是最为理想的.

### 对数复杂度$O(\log n)$

以如下问题为例:对于任意非负整数,统计其二进制展开中数位 1 的总数。如$441=(110111001)_2$。根据右移运算的性质，每右移一位，n 都至少缩减一半^[不是长度，是大小，右移除 2]。也就是说，至多经过$1+\lfloor\log_2\mathrm{n}\rfloor$次循环，$n$必然缩至 0，算法结束。
由大$O$记号定义，在用函数 $\log_r n$ 界定渐进复杂度时，常底数 $r$ 的具体取值无所谓^[常底数无所谓 $\forall\mathrm{~}a,b>1,\mathrm{~}\log_an\mathrm{~}=\boxed{\log_ab}\cdot\log_bn\mathrm{~}=\mathrm{~}\Theta(\log_bn)$]，故通常不予专门标出而笼统地记作$\log n$^[$\forall\left.c>0,\right.\log n^c=\left.c\cdot\log n\right.=\left.\Theta(\log n)\right.$]。
更一般地，凡运行时间可以表示和度量为 $T(n) = O(\log^c n)$ 形式的这一类算法(其中常数 $c>0$ )，均统称作"对数多项式时间复杂度的算法"(polylogarithmic-time algorithm)

### 线性复杂度$O(n)$

凡运行时间可以表示和度量为$T(n) = O(n)$形式的这一类算法，均统称作"线性时间复杂
度算法"(linear-time algorithm)

### 多项式复杂度$O(polynomial(n))$

$\begin{aligned}a_k\cdot n^k+a_{k-1}\cdot n^{k-1}+\cdots+a_2\cdot n^2+a_1\cdot n+a_0~=~\mathcal{O}(n^k),~a_k>0\end{aligned}$
若运行时间可以表示和度量为 $T(n) = O(f(n))$ 的形式，而且 $f(x)$ 为多项式，则对应的算法称作"多项式时间复杂度算法"(polynomial-time algorithm)

### 指数复杂度$O(2^n)$

一般地，凡运行时间可以表示和度量为 $T(n) = O(a^n)$ 形式的算法 $(a > 1)$，均属于"指数时间复杂度算法"(exponential-time algorithm)

### 复杂度层次

![20240309152742](https://yjc-figure.oss-cn-beijing.aliyuncs.com/20240309152742.png)
复杂度的典型层次

$$
\log n < \sqrt{n} < n < n \log n < n^2 < n^3 < 2^n
$$

## 递归
